{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "MaleehaADF"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/Get Files Name Dynamically')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata of Sales Files",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "az_ADLS_SalesInput",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata of Sales Files",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata of Sales Files').output.childItems",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Copy data",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "DelimitedTextSource",
											"storeSettings": {
												"type": "AzureBlobFSReadSettings",
												"recursive": true,
												"enablePartitionDiscovery": false
											},
											"formatSettings": {
												"type": "DelimitedTextReadSettings"
											}
										},
										"sink": {
											"type": "DelimitedTextSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "DelimitedTextWriteSettings",
												"quoteAllText": true,
												"fileExtension": ".txt"
											}
										},
										"enableStaging": false,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "az_ADLS_SalesFiles",
											"type": "DatasetReference",
											"parameters": {
												"FileName": {
													"value": "@item().name",
													"type": "Expression"
												}
											}
										}
									],
									"outputs": [
										{
											"referenceName": "az_ADLS_SalesOutput",
											"type": "DatasetReference",
											"parameters": {}
										}
									]
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Get Metadata of File')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata of Employee Text file",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "Employee_Input",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"lastModified",
								"itemName",
								"itemType",
								"columnCount",
								"size"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Lookup and If Condition')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata of Employee Text file",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "Employee_Input",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"lastModified",
								"itemName"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "Get Last Execution Date",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "Get Metadata of Employee Text file",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderStoredProcedureName": "[[dbo].[sp_GetExecutionDate]",
								"storedProcedureParameters": {
									"Name": {
										"type": "String",
										"value": {
											"value": "@activity('Get Metadata of Employee Text file').output.itemName",
											"type": "Expression"
										}
									}
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "Az_SQL_Database_dbo_emp",
								"type": "DatasetReference",
								"parameters": {}
							}
						}
					},
					{
						"name": "Get LastModifyDate",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "Get Last Execution Date",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@greaterOrEquals(\n   string(activity('Get Last Execution Date').output.firstRow)\n   , string(\n        activity('Get Metadata of Employee Text file').output.lastModified)\n    )",
								"type": "Expression"
							},
							"ifFalseActivities": [
								{
									"name": "False",
									"type": "Wait",
									"dependsOn": [],
									"userProperties": [],
									"typeProperties": {
										"waitTimeInSeconds": 1
									}
								}
							],
							"ifTrueActivities": [
								{
									"name": "sp_UpdateExecutionDate",
									"type": "SqlServerStoredProcedure",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"storedProcedureName": "[[dbo].[sp_UpdateExecutionDate]",
										"storedProcedureParameters": {
											"ExecutionDate": {
												"value": {
													"value": "@convertFromUtc(pipeline().TriggerTime,'Eastern Standard Time')",
													"type": "Expression"
												},
												"type": "DateTime"
											}
										}
									},
									"linkedServiceName": {
										"referenceName": "adfdbLS",
										"type": "LinkedServiceReference"
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Validate Schema')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Emp Metadata",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "az_ADLS_emp1",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"structure"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "Emp_Ref Metadata",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "az_ADLS_emp_ref",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"structure"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "Match Schemas",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "Emp Metadata",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Emp_Ref Metadata",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(activity('Emp_Ref Metadata').output.structure, activity('Emp Metadata').output.structure)",
								"type": "Expression"
							},
							"ifFalseActivities": [
								{
									"name": "Wait False",
									"type": "Wait",
									"dependsOn": [],
									"userProperties": [],
									"typeProperties": {
										"waitTimeInSeconds": 1
									}
								}
							],
							"ifTrueActivities": [
								{
									"name": "True",
									"type": "Wait",
									"dependsOn": [],
									"userProperties": [],
									"typeProperties": {
										"waitTimeInSeconds": 1
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DF Increment Keys')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "az_ADLS_all_emp",
								"type": "DatasetReference"
							},
							"name": "ConsolidateEmployees"
						},
						{
							"dataset": {
								"referenceName": "az_ADLS_Emp3",
								"type": "DatasetReference"
							},
							"name": "Emp3"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "az_ADLS_all_emp",
								"type": "DatasetReference"
							},
							"name": "ConsolidatedEmployees"
						}
					],
					"transformations": [
						{
							"name": "AddDummyColumn"
						},
						{
							"name": "GetMaxID"
						},
						{
							"name": "JoinBothSources"
						},
						{
							"name": "AddIDColumn"
						},
						{
							"name": "AddIDandMaxID"
						},
						{
							"name": "RemoveUnnecessaryColumns"
						},
						{
							"name": "MergeEmp3intoConsolidatedEmployee"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as string,",
						"          { Name} as string,",
						"          { Country} as string,",
						"          { Department} as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> ConsolidateEmployees",
						"source(output(",
						"          Name as string,",
						"          { Country} as string,",
						"          { Department} as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Emp3",
						"ConsolidateEmployees derive(Dummy = 'Dummy') ~> AddDummyColumn",
						"AddDummyColumn aggregate(groupBy(Dummy),",
						"     MaxID = max(EmpID)) ~> GetMaxID",
						"GetMaxID, Emp3 join(1==1,",
						"     joinType:'cross',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> JoinBothSources",
						"JoinBothSources keyGenerate(output(id as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> AddIDColumn",
						"AddIDColumn derive(EmpID = toString(toInteger(id) + toInteger(MaxID))) ~> AddIDandMaxID",
						"AddIDandMaxID select(mapColumn(",
						"          EmpID,",
						"          Name,",
						"          { Country},",
						"          { Department}",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RemoveUnnecessaryColumns",
						"ConsolidateEmployees, RemoveUnnecessaryColumns union(byName: false)~> MergeEmp3intoConsolidatedEmployee",
						"MergeEmp3intoConsolidatedEmployee sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          EmpID as string,",
						"          { Name} as string,",
						"          { Country} as string,",
						"          { Department} as string",
						"     ),",
						"     partitionFileNames:['ConsolidatedEmployee.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> ConsolidatedEmployees"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DF LogADF')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "az_ADLS_dummy",
								"type": "DatasetReference"
							},
							"name": "DummySource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "az_ADLS_Log",
								"type": "DatasetReference"
							},
							"name": "ADFLogFile"
						}
					],
					"transformations": [
						{
							"name": "ParametersValue"
						},
						{
							"name": "RemoveDummyColumn"
						}
					],
					"scriptLines": [
						"parameters{",
						"     ADFName as string,",
						"     PipeLineName as string,",
						"     RunID as string,",
						"     Status as string,",
						"     TriggerName as string,",
						"     logFileName as string",
						"}",
						"source(output(",
						"          Column_1 as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> DummySource",
						"DummySource derive(ADFName = $ADFName,",
						"          PipeLineName = $PipeLineName,",
						"          RunId = $RunID,",
						"          Status = $Status,",
						"          TriggerName = $TriggerName) ~> ParametersValue",
						"ParametersValue select(mapColumn(",
						"          ADFName,",
						"          PipeLineName,",
						"          RunId,",
						"          Status,",
						"          TriggerName",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RemoveDummyColumn",
						"RemoveDummyColumn sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:[($logFileName)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> ADFLogFile"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DF LogADF_append')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "az_ADLS_dummy",
								"type": "DatasetReference"
							},
							"name": "DummySource"
						},
						{
							"dataset": {
								"referenceName": "az_ADLS_logfile",
								"type": "DatasetReference"
							},
							"name": "logfile"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "az_ADLS_Log",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "ParametersValue"
						},
						{
							"name": "RemoveDummyColumn"
						},
						{
							"name": "union"
						}
					],
					"scriptLines": [
						"parameters{",
						"     ADFName as string,",
						"     PipeLineName as string,",
						"     RunID as string,",
						"     Status as string,",
						"     TriggerName as string,",
						"     logFileName as string",
						"}",
						"source(output(",
						"          Column_1 as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> DummySource",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     wildcardPaths:[($logFileName)]) ~> logfile",
						"DummySource derive(ADFName = $ADFName,",
						"          PipeLineName = $PipeLineName,",
						"          RunId = $RunID,",
						"          Status = $Status,",
						"          TriggerName = $TriggerName) ~> ParametersValue",
						"ParametersValue select(mapColumn(",
						"          ADFName,",
						"          PipeLineName,",
						"          RunId,",
						"          Status,",
						"          TriggerName",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RemoveDummyColumn",
						"RemoveDummyColumn, logfile union(byName: true)~> union",
						"union sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:[($logFileName)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DF SCD1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Az_SQL_Database_dbo_emp",
								"type": "DatasetReference"
							},
							"name": "Emp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "az_SQL_DimEmployee",
								"type": "DatasetReference"
							},
							"name": "DimEmployee"
						}
					],
					"transformations": [
						{
							"name": "Upsert"
						}
					],
					"scriptLines": [
						"source(output(",
						"          ID as integer,",
						"          FirstName as string,",
						"          LastName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> Emp",
						"Emp alterRow(upsertIf(1==1)) ~> Upsert",
						"Upsert sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          ID as integer,",
						"          FirstName as string,",
						"          LastName as string",
						"     ),",
						"     deletable:false,",
						"     insertable:false,",
						"     updateable:false,",
						"     upsertable:true,",
						"     keys:['ID'],",
						"     format: 'table',",
						"     preSQLs:['SET IDENTITY_INSERT dbo.DimEmployee ON'],",
						"     postSQLs:['SET IDENTITY_INSERT dbo.DimEmployee OFF'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          ID,",
						"          FirstName,",
						"          LastName",
						"     )) ~> DimEmployee"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DF SCD2')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "az_SQL_DimEmployee",
								"type": "DatasetReference"
							},
							"name": "DimEmployee"
						},
						{
							"dataset": {
								"referenceName": "az_SQL_DimEmployeeT2",
								"type": "DatasetReference"
							},
							"name": "DimEmployeeT2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "az_SQL_DimEmployeeT2",
								"type": "DatasetReference"
							},
							"name": "InsertIntoDimEmpT2"
						},
						{
							"dataset": {
								"referenceName": "az_SQL_DimEmployeeT2",
								"type": "DatasetReference"
							},
							"name": "UpdateDimEmpT2"
						}
					],
					"transformations": [
						{
							"name": "StartEndandIsActive"
						},
						{
							"name": "RenameT2Columns"
						},
						{
							"name": "LookupwithT2"
						},
						{
							"name": "GetOnlyMatchingRows"
						},
						{
							"name": "RemoveSourceTableColumn"
						},
						{
							"name": "SetEndDateAndIsActive"
						},
						{
							"name": "UpdateIsActiveandEndDateForMatches"
						}
					],
					"scriptLines": [
						"source(output(",
						"          ID as integer,",
						"          FirstName as string,",
						"          LastName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> DimEmployee",
						"source(output(",
						"          EmployeeT2Key as integer,",
						"          EmpID as integer,",
						"          FirstName as string,",
						"          LastName as string,",
						"          StartDate as timestamp,",
						"          EndDate as timestamp,",
						"          IsActive as boolean",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> DimEmployeeT2",
						"DimEmployee derive(StartDate = currentTimestamp(),",
						"          IsActive = 1) ~> StartEndandIsActive",
						"DimEmployeeT2 select(mapColumn(",
						"          D_EmployeeT2Key = EmployeeT2Key,",
						"          D_EmpID = EmpID,",
						"          D_FirstName = FirstName,",
						"          D_LastName = LastName,",
						"          D_StartDate = StartDate,",
						"          D_EndDate = EndDate,",
						"          D_IsActive = IsActive",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RenameT2Columns",
						"DimEmployee, RenameT2Columns lookup(ID == D_EmpID,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> LookupwithT2",
						"LookupwithT2 filter(!isNull(D_EmpID)) ~> GetOnlyMatchingRows",
						"GetOnlyMatchingRows select(mapColumn(",
						"          D_EmployeeT2Key,",
						"          D_EmpID,",
						"          D_FirstName,",
						"          D_LastName,",
						"          D_StartDate,",
						"          D_EndDate,",
						"          D_IsActive",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RemoveSourceTableColumn",
						"RemoveSourceTableColumn derive(D_EndDate = currentTimestamp(),",
						"          D_IsActive = 0) ~> SetEndDateAndIsActive",
						"SetEndDateAndIsActive alterRow(updateIf(1==1)) ~> UpdateIsActiveandEndDateForMatches",
						"StartEndandIsActive sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          EmployeeT2Key as integer,",
						"          EmpID as integer,",
						"          FirstName as string,",
						"          LastName as string,",
						"          StartDate as timestamp,",
						"          EndDate as timestamp,",
						"          IsActive as boolean",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     saveOrder: 2,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          EmpID = ID,",
						"          FirstName,",
						"          LastName,",
						"          StartDate,",
						"          IsActive",
						"     )) ~> InsertIntoDimEmpT2",
						"UpdateIsActiveandEndDateForMatches sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          EmployeeT2Key as integer,",
						"          EmpID as integer,",
						"          FirstName as string,",
						"          LastName as string,",
						"          StartDate as timestamp,",
						"          EndDate as timestamp,",
						"          IsActive as boolean",
						"     ),",
						"     deletable:false,",
						"     insertable:false,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['EmployeeT2Key'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     saveOrder: 1,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          EmployeeT2Key = D_EmployeeT2Key,",
						"          EmpID = D_EmpID,",
						"          FirstName = D_FirstName,",
						"          LastName = D_LastName,",
						"          StartDate = D_StartDate,",
						"          EndDate = D_EndDate,",
						"          IsActive = D_IsActive",
						"     )) ~> UpdateDimEmpT2"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DF SalesRunningTotal')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "az_ADLS_MaySales_IN",
								"type": "DatasetReference"
							},
							"name": "MaySales"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "az_ADLS_RunningTotal_OU",
								"type": "DatasetReference"
							},
							"name": "SalesRunningTotal"
						}
					],
					"transformations": [
						{
							"name": "CalculateRunningTotal"
						}
					],
					"scriptLines": [
						"source(output(",
						"          SalesDate as string,",
						"          SalesItem as string,",
						"          Country as string,",
						"          Quantity as long",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> MaySales",
						"MaySales window(asc(SalesDate, true),",
						"     RunningTotal = sum(toInteger(Quantity))) ~> CalculateRunningTotal",
						"CalculateRunningTotal sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['SalesRunningTotal.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> SalesRunningTotal"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DF_HandlingErrorRows')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "az_ADLS_GlobalSales_May2020",
								"type": "DatasetReference"
							},
							"name": "GlobalSalesMay2020"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "az_SQL_GlobalSalesBad",
								"type": "DatasetReference"
							},
							"name": "GlobalSalesBad"
						},
						{
							"dataset": {
								"referenceName": "az_SQL_GlobalSales",
								"type": "DatasetReference"
							},
							"name": "GlobalSales"
						}
					],
					"transformations": [
						{
							"name": "ValidateDateColumn"
						},
						{
							"name": "GetFileName"
						},
						{
							"name": "FileNameGoodRows"
						}
					],
					"scriptLines": [
						"source(output(",
						"          SalesDate as string,",
						"          SalesItem as string,",
						"          Country as string,",
						"          Quantity as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     modifiedAfter: (toTimestamp(1673481600000L))) ~> GlobalSalesMay2020",
						"GlobalSalesMay2020 split(isNull(toDate(SalesDate, 'dd-MMM-yyy')),",
						"     disjoint: false) ~> ValidateDateColumn@(ErrorRow, GoodRows)",
						"ValidateDateColumn@ErrorRow derive(FileName = 'Sales_May2020.csv') ~> GetFileName",
						"ValidateDateColumn@GoodRows derive(FileName = 'Sales_May2020.csv',",
						"          SalesDate_Converted = toDate(SalesDate,'dd-MMM-yyyy'),",
						"          Quantity_Converted = toInteger(Quantity)) ~> FileNameGoodRows",
						"GetFileName sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Date as string,",
						"          Item as string,",
						"          Country as string,",
						"          Quantity as string,",
						"          FileName as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          Date = SalesDate,",
						"          Item = SalesItem,",
						"          Country,",
						"          Quantity,",
						"          FileName",
						"     )) ~> GlobalSalesBad",
						"FileNameGoodRows sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Date as date,",
						"          Item as string,",
						"          Country as string,",
						"          Quantity as integer,",
						"          FileName as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          Date = SalesDate_Converted,",
						"          Item = SalesItem,",
						"          Country,",
						"          Quantity = Quantity_Converted,",
						"          FileName",
						"     )) ~> GlobalSales"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Process Fixed Length')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "az_ADLS_emp",
								"type": "DatasetReference"
							},
							"name": "EmpTextFile"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "az_ADLS_emp_output",
								"type": "DatasetReference"
							},
							"name": "CleanEmp"
						}
					],
					"transformations": [
						{
							"name": "DefineColumns"
						},
						{
							"name": "RemoveFirstColumn"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Column_1 as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> EmpTextFile",
						"EmpTextFile derive(EmpID = substring(Column_1, 1, 4),",
						"          EmpName = substring(Column_1, 5, 10),",
						"          State = substring(Column_1, 15, 2),",
						"          Contact = substring(Column_1, 17, 11)) ~> DefineColumns",
						"DefineColumns select(mapColumn(",
						"          EmpID,",
						"          EmpName,",
						"          State,",
						"          Contact",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RemoveFirstColumn",
						"RemoveFirstColumn sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['cleanedemp.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> CleanEmp"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Product Transformation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "az_ADLS_ProductAll",
								"type": "DatasetReference"
							},
							"name": "ProductAll"
						},
						{
							"dataset": {
								"referenceName": "az_ADLS_ProductModel",
								"type": "DatasetReference"
							},
							"name": "ProductModel"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "az_ADLS_ProductFinal",
								"type": "DatasetReference"
							},
							"name": "FinalProduct"
						}
					],
					"transformations": [
						{
							"name": "LookupforProductandProductModel"
						},
						{
							"name": "RemoveDuplicate"
						},
						{
							"name": "RemoveRecordwithZeroPrice"
						}
					],
					"scriptLines": [
						"source(output(",
						"          ProductID as string,",
						"          Name as string,",
						"          ProductNumber as string,",
						"          MakeFlag as string,",
						"          FinishedGoodsFlag as string,",
						"          Color as string,",
						"          SafetyStockLevel as string,",
						"          ReorderPoint as string,",
						"          StandardCost as string,",
						"          ListPrice as string,",
						"          Size as string,",
						"          SizeUnitMeasureCode as string,",
						"          WeightUnitMeasureCode as string,",
						"          Weight as string,",
						"          DaysToManufacture as string,",
						"          ProductLine as string,",
						"          Class as string,",
						"          Style as string,",
						"          ProductSubcategoryID as string,",
						"          ProductModelID as string,",
						"          SellStartDate as string,",
						"          SellEndDate as string,",
						"          DiscontinuedDate as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> ProductAll",
						"source(output(",
						"          ProductModelID as string,",
						"          Name as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> ProductModel",
						"ProductAll, ProductModel lookup(ProductAll@ProductModelID == ProductModel@ProductModelID,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> LookupforProductandProductModel",
						"LookupforProductandProductModel select(mapColumn(",
						"          ProductID,",
						"          Name = ProductAll@Name,",
						"          {Model Name} = ProductModel@Name,",
						"          ProductNumber,",
						"          MakeFlag,",
						"          FinishedGoodsFlag,",
						"          Color,",
						"          SafetyStockLevel,",
						"          ReorderPoint,",
						"          StandardCost,",
						"          ListPrice,",
						"          Size,",
						"          SizeUnitMeasureCode,",
						"          WeightUnitMeasureCode,",
						"          Weight,",
						"          DaysToManufacture,",
						"          ProductLine,",
						"          Class,",
						"          Style,",
						"          ProductSubcategoryID,",
						"          ProductModelID = ProductAll@ProductModelID,",
						"          SellStartDate,",
						"          SellEndDate,",
						"          DiscontinuedDate",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RemoveDuplicate",
						"RemoveDuplicate filter(greater(toInteger(ListPrice), 0)) ~> RemoveRecordwithZeroPrice",
						"RemoveRecordwithZeroPrice sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['FinalProduct.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          ProductID,",
						"          Name,",
						"          {Model Name},",
						"          ProductNumber,",
						"          MakeFlag,",
						"          FinishedGoodsFlag,",
						"          Color,",
						"          SafetyStockLevel,",
						"          ReorderPoint,",
						"          StandardCost,",
						"          ListPrice,",
						"          Size,",
						"          SizeUnitMeasureCode,",
						"          WeightUnitMeasureCode,",
						"          Weight,",
						"          DaysToManufacture,",
						"          ProductLine,",
						"          Class,",
						"          Style,",
						"          ProductSubcategoryID,",
						"          ProductModelID,",
						"          SellStartDate,",
						"          SellEndDate,",
						"          DiscontinuedDate",
						"     ),",
						"     partitionBy('hash', 1)) ~> FinalProduct"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/RemoveDups')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "az_ADLS_emp1",
								"type": "DatasetReference"
							},
							"name": "Emp1"
						},
						{
							"dataset": {
								"referenceName": "az_ADLS_emp2",
								"type": "DatasetReference"
							},
							"name": "Emp2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "az_ADLS_ConsolidatedEmployee",
								"type": "DatasetReference"
							},
							"name": "ConsolidatedEmployee"
						}
					],
					"transformations": [
						{
							"name": "MergeEmp1andEmp2"
						},
						{
							"name": "RemoveDup"
						},
						{
							"name": "Sorting"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as string,",
						"          { Name} as string,",
						"          { Country} as string,",
						"          { Department} as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Emp1",
						"source(output(",
						"          EmpID as string,",
						"          { Name} as string,",
						"          { Country} as string,",
						"          { Department} as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Emp2",
						"Emp1, Emp2 union(byName: true)~> MergeEmp1andEmp2",
						"MergeEmp1andEmp2 aggregate(groupBy(EmpID),",
						"     each(match(name!='EmpID'), $$ = first($$))) ~> RemoveDup",
						"RemoveDup sort(asc(EmpID, false),",
						"     partitionBy('hash', 1)) ~> Sorting",
						"Sorting sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['ConsolidatedEmployee.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> ConsolidatedEmployee"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Execute ADFLogs')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Set FileName",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "Wait1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"variableName": "LogFileName",
							"value": {
								"value": "@concat(formatDateTime(utcnow(),'yyyy-MM-dd'),'_log.csv')",
								"type": "Expression"
							}
						}
					},
					{
						"name": "Get Metadata",
						"type": "GetMetadata",
						"dependsOn": [
							{
								"activity": "Set FileName",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "az_ADLS_logfile",
								"type": "DatasetReference",
								"parameters": {
									"logfileName": {
										"value": "@variables('LogFileName')",
										"type": "Expression"
									}
								}
							},
							"fieldList": [
								"exists"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "Check whether file exists or not",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "Get Metadata",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@activity('Get Metadata').output.exists",
								"type": "Expression"
							},
							"ifFalseActivities": [
								{
									"name": "DF LogADF",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "DF LogADF",
											"type": "DataFlowReference",
											"parameters": {
												"ADFName": {
													"value": "'@{pipeline().DataFactory}'",
													"type": "Expression"
												},
												"PipeLineName": {
													"value": "'@{pipeline().Pipeline}'",
													"type": "Expression"
												},
												"RunID": {
													"value": "'@{pipeline().RunId}'",
													"type": "Expression"
												},
												"Status": {
													"value": "'@{string('Success')}'",
													"type": "Expression"
												},
												"TriggerName": {
													"value": "'@{pipeline().TriggerName}'",
													"type": "Expression"
												},
												"logFileName": {
													"value": "'@{variables('LogFileName')}'",
													"type": "Expression"
												}
											},
											"datasetParameters": {
												"DummySource": {},
												"ADFLogFile": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								}
							],
							"ifTrueActivities": [
								{
									"name": "DF LogADF_append",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "DF LogADF_append",
											"type": "DataFlowReference",
											"parameters": {
												"ADFName": {
													"value": "'@{pipeline().DataFactory}'",
													"type": "Expression"
												},
												"PipeLineName": {
													"value": "'@{pipeline().Pipeline}'",
													"type": "Expression"
												},
												"RunID": {
													"value": "'@{pipeline().RunId}'",
													"type": "Expression"
												},
												"Status": {
													"value": "'@{string('Success')}'",
													"type": "Expression"
												},
												"TriggerName": {
													"value": "'@{pipeline().TriggerName}'",
													"type": "Expression"
												},
												"logFileName": {
													"value": "'@{variables('LogFileName')}'",
													"type": "Expression"
												}
											},
											"datasetParameters": {
												"DummySource": {},
												"logfile": {
													"logfileName": {
														"value": "@variables('LogFileName')",
														"type": "Expression"
													}
												},
												"sink1": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								}
							]
						}
					},
					{
						"name": "Wait1",
						"type": "Wait",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"waitTimeInSeconds": 3
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"variables": {
					"LogFileName": {
						"type": "String"
					}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/DF LogADF')]",
				"[concat(variables('factoryId'), '/dataflows/DF LogADF_append')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Execute DF ConsolidatedEmployee')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "ConsolidatedEmployee",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "RemoveDups",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"Emp1": {},
									"Emp2": {},
									"ConsolidatedEmployee": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 16,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/RemoveDups')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Execute DF IncrementKeys')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "DF IncrementKeys",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "DF Increment Keys",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"ConsolidateEmployees": {},
									"Emp3": {},
									"ConsolidatedEmployees": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/DF Increment Keys')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Execute DF SCD1')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "DF SCD1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "DF SCD1",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"Emp": {},
									"DimEmployee": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/DF SCD1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Execute DF SalesRunningTotal')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "DF SalesRunningTotal",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "DF SalesRunningTotal",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"MaySales": {},
									"SalesRunningTotal": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/DF SalesRunningTotal')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Execute DF_HandlingErrorRows')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "DF_HandlingErrorRows",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "DF_HandlingErrorRows",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"GlobalSalesMay2020": {},
									"GlobalSalesBad": {},
									"GlobalSales": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 16,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/DF_HandlingErrorRows')]"
			]
		}
	]
}